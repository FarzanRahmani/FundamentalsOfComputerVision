{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ابتدا کتابخانه های لازم را ایمپورت میکنیم."
      ],
      "metadata": {
        "id": "4D6qwmBVu-AL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kXLI8NyPhLaT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import shutil\n",
        "from zipfile import ZipFile\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import glob\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "سپس گوگل درایو را mount میکنیم."
      ],
      "metadata": {
        "id": "hJslKDVlvIdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sA0ohoYDvOlZ",
        "outputId": "e77863f8-49c3-4877-8925-d083b1eea74d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "حال پوشه مورد نظر برای ترین کردن مدل را میسازیم."
      ],
      "metadata": {
        "id": "QXNi7rAGywca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_root = '/content/data'\n",
        "\n",
        "if not os.path.isdir(data_root):\n",
        "    os.mkdir(data_root)"
      ],
      "metadata": {
        "id": "O9RvWLpGvUz5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "در اینجا لیبل هایی که در داخل گوگل درایو گذاشتیم را میخوانیم و همچنین فیلم مربوطه را خوانده و فریم های آن را جدا کرده و پس از آن آنها را در جای مناسب مطابق به مدل یولو قرار میدهیم."
      ],
      "metadata": {
        "id": "hRlGBnQQy2Az"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vidcap = cv2.VideoCapture('/content/drive/MyDrive/3Birds_inCage_stable(easy) (2).mp4')\n",
        "success,image = vidcap.read()\n",
        "\n",
        "count = 0\n",
        "\n",
        "feameLabel = '/content/data/obj'\n",
        "label_cvat_root = '/content/drive/MyDrive/obj_train_data'\n",
        "if not os.path.isdir(feameLabel):\n",
        "    os.mkdir(feameLabel)\n",
        "while success:\n",
        "  if( count >= 1400):\n",
        "    frame_name = f\"frame_00{count}\"\n",
        "\n",
        "    frame_path = os.path.join(feameLabel, f\"{frame_name}.jpg\")\n",
        "    cv2.imwrite(frame_path, image)     # JPEG\n",
        "    label_path = os.path.join(feameLabel, f\"{frame_name}.txt\")\n",
        "    label_cvat = os.path.join(label_cvat_root, f\"{frame_name}.txt\")\n",
        "\n",
        "    with open(label_cvat) as f:\n",
        "      with open(label_path, \"w\") as f1:\n",
        "        for line in f:\n",
        "            f1.write(line)\n",
        "  success,image = vidcap.read()\n",
        "  count += 1"
      ],
      "metadata": {
        "id": "vPjLKbyxvadu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preparing the folder structure\n",
        "\n",
        "full_data_path = '/content/data/obj/'\n",
        "extension_allowed = '.jpg'\n",
        "split_percentage = 88\n",
        "\n",
        "images_path = '/content/data/images/'\n",
        "if os.path.exists(images_path):\n",
        "    shutil.rmtree(images_path)\n",
        "os.mkdir(images_path)\n",
        "\n",
        "labels_path = '/content/data/labels/'\n",
        "if os.path.exists(labels_path):\n",
        "    shutil.rmtree(labels_path)\n",
        "os.mkdir(labels_path)\n",
        "\n",
        "training_images_path = images_path + 'training/'\n",
        "validation_images_path = images_path + 'validation/'\n",
        "training_labels_path = labels_path + 'training/'\n",
        "validation_labels_path = labels_path +'validation/'\n",
        "\n",
        "os.mkdir(training_images_path)\n",
        "os.mkdir(validation_images_path)\n",
        "os.mkdir(training_labels_path)\n",
        "os.mkdir(validation_labels_path)\n",
        "\n",
        "files = []\n",
        "\n",
        "ext_len = len(extension_allowed)\n",
        "\n",
        "for r, d, f in os.walk(full_data_path):\n",
        "    for file in f:\n",
        "        if file.endswith(extension_allowed):\n",
        "            strip = file[0:len(file) - ext_len]\n",
        "            files.append(strip)\n",
        "\n",
        "random.shuffle(files)\n",
        "\n",
        "size = len(files)\n",
        "\n",
        "split = int(split_percentage * size / 100)\n",
        "\n",
        "# copying training data\n",
        "for i in range(split):\n",
        "    strip = files[i]\n",
        "\n",
        "    image_file = strip + extension_allowed\n",
        "    src_image = full_data_path + image_file\n",
        "    shutil.copy(src_image, training_images_path)\n",
        "\n",
        "    annotation_file = strip + '.txt'\n",
        "    src_label = full_data_path + annotation_file\n",
        "    shutil.copy(src_label, training_labels_path)\n",
        "\n",
        "# copying validation data\n",
        "for i in range(split, size):\n",
        "    strip = files[i]\n",
        "\n",
        "    image_file = strip + extension_allowed\n",
        "    src_image = full_data_path + image_file\n",
        "    shutil.copy(src_image, validation_images_path)\n",
        "\n",
        "    annotation_file = strip + '.txt'\n",
        "    src_label = full_data_path + annotation_file\n",
        "    shutil.copy(src_label, validation_labels_path)"
      ],
      "metadata": {
        "id": "ipFROJSiwNHh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cloning yolov5\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt  # install dependencies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHEP90oTvRdS",
        "outputId": "4f4f1885-74fa-43fe-b05e-aa19083c55fa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 15814, done.\u001b[K\n",
            "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
            "remote: Total 15814 (delta 9), reused 23 (delta 2), pack-reused 15768\u001b[K\n",
            "Receiving objects: 100% (15814/15814), 14.64 MiB | 18.81 MiB/s, done.\n",
            "Resolving deltas: 100% (10821/10821), done.\n",
            "/content/yolov5\n",
            "Collecting gitpython>=3.1.30 (from -r requirements.txt (line 5))\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.25.1)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.7.0.72)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (8.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (6.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.27.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.11.1)\n",
            "Collecting thop>=0.1.1 (from -r requirements.txt (line 14))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.15.2+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (4.65.0)\n",
            "Collecting ultralytics>=8.0.111 (from -r requirements.txt (line 18))\n",
            "  Downloading ultralytics-8.0.131-py3-none-any.whl (626 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m626.9/626.9 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (0.12.2)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (67.7.2)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30->-r requirements.txt (line 5))\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->-r requirements.txt (line 15)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->-r requirements.txt (line 15)) (16.0.6)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2022.7.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5))\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->-r requirements.txt (line 15)) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->-r requirements.txt (line 15)) (1.3.0)\n",
            "Installing collected packages: smmap, gitdb, gitpython, ultralytics, thop\n",
            "Successfully installed gitdb-4.0.10 gitpython-3.1.31 smmap-5.0.0 thop-0.1.1.post2209072238 ultralytics-8.0.131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iH-A3A_O6g1M",
        "outputId": "dfac0d21-94b1-4826-8f1e-9460f155eb79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# number_of_epochs = 50  # desired in question\n",
        "\n",
        "# but due to the limit of time we use following:\n",
        "# number_of_epochs = 2  # limited time :("
      ],
      "metadata": {
        "id": "3TSd3CbBpmLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 640 --batch 2 --epochs 2 --data /content/dataset.yaml --weights yolov5s.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlhF_JrYwZ4P",
        "outputId": "0a08d19b-0e89-4384-ec7d-7eebcf218984"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/dataset.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=2, batch_size=2, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-193-g485da42 Python-3.10.12 torch-2.0.1+cu118 CPU\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 18.8MB/s]\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 135MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data/labels/training... 529 images, 0 backgrounds, 0 corrupt: 100% 529/529 [00:00<00:00, 1369.03it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data/labels/training.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data/labels/validation... 73 images, 0 backgrounds, 0 corrupt: 100% 73/73 [00:00<00:00, 488.13it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/data/labels/validation.cache\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.76 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 2 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/1         0G      0.107    0.04601          0         12        640: 100% 265/265 [15:16<00:00,  3.46s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 19/19 [00:30<00:00,  1.61s/it]\n",
            "                   all         73        219      0.204      0.557       0.22     0.0535\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/1         0G     0.0774    0.03577          0          2        640: 100% 265/265 [15:10<00:00,  3.44s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "                   all         73        219      0.336      0.602      0.335     0.0827\n",
            "\n",
            "2 epochs completed in 0.524 hours.\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 14.3MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 14.3MB\n",
            "\n",
            "Validating runs/train/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 19/19 [00:29<00:00,  1.54s/it]\n",
            "                   all         73        219      0.335      0.603      0.333     0.0824\n",
            "Results saved to \u001b[1mruns/train/exp\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}